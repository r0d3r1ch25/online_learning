apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: online-learning-cron-v0
spec:
  schedule: "* * * * *"  # Every minute (standard 5-field cron format)
  timezone: "UTC"
  successfulJobsHistoryLimit: 25  # Keep last 25 successful workflows
  failedJobsHistoryLimit: 5       # Keep last 5 failed workflows
  workflowSpec:
    entrypoint: python-pipeline
    templates:
    - name: python-pipeline
      script:
        image: python:3.11-alpine
        command: ["python"]
        source: |
          import urllib.request
          import json
          import datetime
          import sys
          
          print(f"=== PIPELINE START: {datetime.datetime.now()} ===", flush=True)
          
          try:
              # Get observation
              print("[1/4] Fetching observation from ingestion service...", flush=True)
              req = urllib.request.Request("http://ingestion-service.ml-services.svc.cluster.local:8002/next")
              with urllib.request.urlopen(req, timeout=10) as response:
                  observation = json.loads(response.read().decode())
              
              actual_value = observation['target']
              obs_id = observation.get('observation_id', 'N/A')
              remaining = observation.get('remaining', 'N/A')
              print(f"SUCCESS: Observation {obs_id}: target={actual_value}, remaining={remaining}", flush=True)
              
              # Get features
              print("[2/4] Extracting features from feature service...", flush=True)
              feature_data = json.dumps({"series_id": "argo_python_pipeline", "value": actual_value})
              req = urllib.request.Request(
                  "http://feature-service.ml-services.svc.cluster.local:8001/add",
                  data=feature_data.encode(),
                  headers={'Content-Type': 'application/json'}
              )
              with urllib.request.urlopen(req, timeout=10) as response:
                  feature_result = json.loads(response.read().decode())
              
              features = feature_result['features']
              available_lags = feature_result.get('available_lags', 0)
              print(f"SUCCESS: Features extracted: {len(features)} inputs, {available_lags} lags available", flush=True)
              
              # Show first few features for debugging
              feature_sample = {k: v for k, v in list(features.items())[:5]}
              print(f"  Sample features: {feature_sample}...", flush=True)
              
              # Predict and learn
              print("[3/4] Sending to model service (predict_learn)...", flush=True)
              model_data = json.dumps({
                  "features": features,
                  "target": feature_result['target']
              })
              print(f"  Model input: features={len(features)} keys, target={feature_result['target']}", flush=True)
              
              req = urllib.request.Request(
                  "http://model-service.ml-services.svc.cluster.local:8000/predict_learn",
                  data=model_data.encode(),
                  headers={'Content-Type': 'application/json'}
              )
              with urllib.request.urlopen(req, timeout=10) as response:
                  model_result = json.loads(response.read().decode())
              
              prediction = model_result['prediction']
              error = actual_value - prediction
              print(f"SUCCESS: Model prediction: {prediction:.4f}", flush=True)
              print(f"  Actual: {actual_value} | Prediction: {prediction:.4f} | Error: {error:.4f}", flush=True)
              
              # Get updated metrics
              print("[4/4] Fetching updated model metrics...", flush=True)
              req = urllib.request.Request("http://model-service.ml-services.svc.cluster.local:8000/model_metrics")
              with urllib.request.urlopen(req, timeout=10) as response:
                  metrics = json.loads(response.read().decode())
              
              if 'default' in metrics:
                  m = metrics['default']
                  print(f"SUCCESS: Updated metrics: MAE={m.get('mae', 0):.4f}, RMSE={m.get('rmse', 0):.4f}, Count={m.get('count', 0)}", flush=True)
              
              print(f"=== PIPELINE COMPLETE: {datetime.datetime.now()} ===", flush=True)
              
          except Exception as e:
              print(f"ERROR: {e}", flush=True)
              if "HTTP Error 204" in str(e):
                  print("INFO: No more observations available - stream exhausted", flush=True)
                  sys.exit(0)  # Normal exit for stream exhaustion
              else:
                  sys.exit(1)  # Error exit for actual failures
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"